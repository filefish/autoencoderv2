{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "from __future__ import print_function\n",
    "import argparse\n",
    "import torch\n",
    "import torch.utils.data\n",
    "from torch import nn, optim\n",
    "from torch.nn import functional as F\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.utils import save_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "\n",
    "parser = argparse.ArgumentParser(description=\"VAE MNIST EXAMPLE\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "_StoreAction(option_strings=['--batch-size2'], dest='batch_size2', nargs=None, const=None, default=128, type=<class 'int'>, choices=None, help='input batch size for training (default: 128)', metavar='N')"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 6
    }
   ],
   "source": [
    "parser.add_argument('--batch-size2', type=int, default=128, metavar='N',\n",
    "help='input batch size for training (default: 128)')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "_StoreAction(option_strings=['--log-interval'], dest='log_interval', nargs=None, const=None, default=10, type=<class 'int'>, choices=None, help='how many batches to wait before logging training status', metavar='N')"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 7
    }
   ],
   "source": [
    "parser.add_argument('--epochs', type=int, default=10, metavar='N',\n",
    "                    help='number of epochs to train (default: 10)')\n",
    "parser.add_argument('--no-cuda', action='store_true', default=False,\n",
    "                    help='enables CUDA training')\n",
    "parser.add_argument('--seed', type=int, default=1, metavar='S',\n",
    "                    help='random seed (default: 1)')\n",
    "parser.add_argument('--log-interval', type=int, default=10, metavar='N',\n",
    "help='how many batches to wait before logging training status')\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "\n",
    "args = parser.parse_args(args=['--batch-size2','128','--epochs','10'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "args.cuda = not args.no_cuda and torch.cuda.is_available()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "torch.manual_seed(args.seed)\n",
    "\n",
    "device = torch.device(\"cuda\" if args.cuda else \"cpu\")\n",
    "\n",
    "kwargs = {'num_workers':1, 'pin_memory':True} if args.cuda else {}\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST('../data',train=True,download=True,\n",
    "                   transform=transforms.ToTensor()),\n",
    "    batch_size=args.batch_size2,shuffle=True,**kwargs)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST('../data',train=False,transform=transforms.ToTensor()),\n",
    "    batch_size=args.batch_size2,shuffle=True,**kwargs)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "data": {
      "text/plain": "128"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 19
    }
   ],
   "source": [
    "args.batch_size2"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "\n",
    "class VAE(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(VAE, self).__init__()\n",
    "        \n",
    "        self.fc1 = nn.Linear(784,400)\n",
    "        self.fc21 = nn.Linear(400,20)\n",
    "        self.fc22 = nn.Linear(400,20)\n",
    "        self.fc3 = nn.Linear(20,400)\n",
    "        self.fc4 = nn.Linear(400,784)\n",
    "        \n",
    "    def encode(self, x):\n",
    "        h1 = F.relu(self.fc1(x))\n",
    "        return self.fc21(h1), self.fc22(h1)\n",
    "    #入力から中心と分散の対数を作っている\n",
    "    \n",
    "    def reparameterize(self,mu,logvar):\n",
    "        std = torch.exp(0.5*logvar)\n",
    "        eps = torch.randn_like(std)\n",
    "        #torch.randn_like(std)はstdと同じ次元の正規乱数を与えている。N(0,1)**size(std)\n",
    "        return mu + eps*std\n",
    "    #zの値を確率的に作っている。\n",
    "    \n",
    "    def decode(self,z):\n",
    "        h3 = F.relu(self.fc3(z))\n",
    "        return torch.sigmoid(self.fc4(h3))\n",
    "    #zからNNを通したあとに、sigmoidで押し込んでxの値を作っている\n",
    "    \n",
    "    def forward(self, x):\n",
    "        mu, logvar = self.encode(x.view(-1,784))\n",
    "        z = self.reparameterize(mu, logvar)\n",
    "        return self.decode(z),mu,logvar\n",
    "    #出力はxの予測値とzを算出するときの中心と分散になっている\n",
    "    \n",
    "model = VAE().to(device)\n",
    "optimizer = optim.Adam(model.parameters(),lr=1e-3)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "def loss_function(recon_x,x,mu,logvar):\n",
    "    BCE = F.binary_cross_entropy(recon_x,x.view(-1,784),reduction='sum')\n",
    "    #recon_xはsigmoidをdecordeで通されているので、[0,1]になっている。\n",
    "    KLD = -0.5*torch.sum(1+logvar-mu.pow(2)-logvar.exp())\n",
    "    \n",
    "    return BCE+KLD"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "\n",
    "def train(epoch):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    for batch_idx, (data,_) in enumerate(train_loader):\n",
    "        #ラベルは使わないようだ\n",
    "        data = data.to(device)\n",
    "        #データをGPUにおくる\n",
    "        optimizer.zero_grad()\n",
    "        #傾きの初期化\n",
    "        recon_batch, mu, logvar = model(data)\n",
    "        #VAEからバッヂ分のデータと中心と分散のログを受け取る\n",
    "        loss = loss_function(recon_batch,data,mu,logvar)\n",
    "        #バッヂ分のロスを計算。バッヂ数で割っていないようだ。書き出しのときにデータ数で割っている。\n",
    "        loss.backward()\n",
    "        #傾きを計算\n",
    "        train_loss+= loss.item()\n",
    "        optimizer.step()\n",
    "        #パラメータの更新\n",
    "        if batch_idx % args.log_interval ==0:\n",
    "            #一定間隔でロスを書き出し\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "              epoch,batch_idx*len(data),len(train_loader.dataset),\n",
    "                100.*batch_idx/len(train_loader),\n",
    "                loss.item()/len(data)\n",
    "            ))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [
    "\n",
    "def test(epoch):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    with torch.no_grad():#バックプロパゲーションを行わないから、微分情報を残さない\n",
    "        for i, (data, _) in enumerate(test_loader):\n",
    "            #テストデータを取り出す。ラベルはいらない。\n",
    "            data =data.to(device)\n",
    "            #データをGPUに送る\n",
    "            recon_batch, mu, logvar = model(data)\n",
    "            #データからバッヂ分の再現画像と中心と分散の対数を出している。\n",
    "            test_loss += loss_function(recon_batch,data,mu,logvar).item()\n",
    "            #テストデータでのロスを出している\n",
    "            if i == 0:\n",
    "                #はじめのバッヂについて\n",
    "                n = min(data.size(0),16)\n",
    "                #nをバッヂのデータ数か８との小さい方として\n",
    "                comparizon = torch.cat([data[:n],recon_batch.view(args.batch_size2,1,28,28)[:n]])\n",
    "                #元データと再現データを並べる\n",
    "                save_image(comparizon.cpu(),'./results/reconstruction_' + str(epoch) + '.png',nrow=n)\n",
    "                \n",
    "                test_loss /= len(test_loader.dataset)\n",
    "                print('====> Test set loss: {:.4f}'.format(test_loss))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "data": {
      "text/plain": "20"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 30
    }
   ],
   "source": [
    "args.epochs=20\n",
    "args.epochs"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 101.927040\nTrain Epoch: 1 [1280/60000 (2%)]\tLoss: 102.578384\n",
      "Train Epoch: 1 [2560/60000 (4%)]\tLoss: 101.506149\nTrain Epoch: 1 [3840/60000 (6%)]\tLoss: 98.650948\n",
      "Train Epoch: 1 [5120/60000 (9%)]\tLoss: 97.793457\nTrain Epoch: 1 [6400/60000 (11%)]\tLoss: 103.184891\n",
      "Train Epoch: 1 [7680/60000 (13%)]\tLoss: 99.731468\nTrain Epoch: 1 [8960/60000 (15%)]\tLoss: 101.639252\n",
      "Train Epoch: 1 [10240/60000 (17%)]\tLoss: 100.950104\nTrain Epoch: 1 [11520/60000 (19%)]\tLoss: 99.981804\nTrain Epoch: 1 [12800/60000 (21%)]\tLoss: 102.596817\n",
      "Train Epoch: 1 [14080/60000 (23%)]\tLoss: 101.299881\nTrain Epoch: 1 [15360/60000 (26%)]\tLoss: 94.809441\nTrain Epoch: 1 [16640/60000 (28%)]\tLoss: 102.212860\n",
      "Train Epoch: 1 [17920/60000 (30%)]\tLoss: 102.460861\nTrain Epoch: 1 [19200/60000 (32%)]\tLoss: 101.338280\n",
      "Train Epoch: 1 [20480/60000 (34%)]\tLoss: 104.402313\nTrain Epoch: 1 [21760/60000 (36%)]\tLoss: 102.336838\nTrain Epoch: 1 [23040/60000 (38%)]\tLoss: 101.812355\n",
      "Train Epoch: 1 [24320/60000 (41%)]\tLoss: 103.321304\nTrain Epoch: 1 [25600/60000 (43%)]\tLoss: 104.160583\nTrain Epoch: 1 [26880/60000 (45%)]\tLoss: 100.239304\n",
      "Train Epoch: 1 [28160/60000 (47%)]\tLoss: 100.125778\nTrain Epoch: 1 [29440/60000 (49%)]\tLoss: 102.330147\n",
      "Train Epoch: 1 [30720/60000 (51%)]\tLoss: 101.725266\nTrain Epoch: 1 [32000/60000 (53%)]\tLoss: 102.624268\n",
      "Train Epoch: 1 [33280/60000 (55%)]\tLoss: 104.964691\nTrain Epoch: 1 [34560/60000 (58%)]\tLoss: 103.889359\nTrain Epoch: 1 [35840/60000 (60%)]\tLoss: 98.670959\n",
      "Train Epoch: 1 [37120/60000 (62%)]\tLoss: 100.761826\nTrain Epoch: 1 [38400/60000 (64%)]\tLoss: 97.928757\n",
      "Train Epoch: 1 [39680/60000 (66%)]\tLoss: 101.881744\nTrain Epoch: 1 [40960/60000 (68%)]\tLoss: 99.373894\n",
      "Train Epoch: 1 [42240/60000 (70%)]\tLoss: 97.781403\nTrain Epoch: 1 [43520/60000 (72%)]\tLoss: 100.834785\n",
      "Train Epoch: 1 [44800/60000 (75%)]\tLoss: 103.785995\nTrain Epoch: 1 [46080/60000 (77%)]\tLoss: 102.612442\n",
      "Train Epoch: 1 [47360/60000 (79%)]\tLoss: 102.220520\nTrain Epoch: 1 [48640/60000 (81%)]\tLoss: 103.178490\n",
      "Train Epoch: 1 [49920/60000 (83%)]\tLoss: 102.213753\nTrain Epoch: 1 [51200/60000 (85%)]\tLoss: 102.649170\n",
      "Train Epoch: 1 [52480/60000 (87%)]\tLoss: 101.224548\nTrain Epoch: 1 [53760/60000 (90%)]\tLoss: 102.908493\nTrain Epoch: 1 [55040/60000 (92%)]\tLoss: 106.346786\n",
      "Train Epoch: 1 [56320/60000 (94%)]\tLoss: 101.320488\nTrain Epoch: 1 [57600/60000 (96%)]\tLoss: 100.157127\n",
      "Train Epoch: 1 [58880/60000 (98%)]\tLoss: 102.319397\n",
      "====> Test set loss: 1.2649\n",
      "Train Epoch: 2 [0/60000 (0%)]\tLoss: 101.347366\nTrain Epoch: 2 [1280/60000 (2%)]\tLoss: 98.197266\n",
      "Train Epoch: 2 [2560/60000 (4%)]\tLoss: 106.162659\nTrain Epoch: 2 [3840/60000 (6%)]\tLoss: 103.258354\nTrain Epoch: 2 [5120/60000 (9%)]\tLoss: 101.831421\n",
      "Train Epoch: 2 [6400/60000 (11%)]\tLoss: 102.415070\nTrain Epoch: 2 [7680/60000 (13%)]\tLoss: 98.103615\nTrain Epoch: 2 [8960/60000 (15%)]\tLoss: 99.675331\n",
      "Train Epoch: 2 [10240/60000 (17%)]\tLoss: 103.019287\nTrain Epoch: 2 [11520/60000 (19%)]\tLoss: 98.271301\n",
      "Train Epoch: 2 [12800/60000 (21%)]\tLoss: 102.670723\nTrain Epoch: 2 [14080/60000 (23%)]\tLoss: 103.094383\n",
      "Train Epoch: 2 [15360/60000 (26%)]\tLoss: 103.312531\nTrain Epoch: 2 [16640/60000 (28%)]\tLoss: 102.576828\n",
      "Train Epoch: 2 [17920/60000 (30%)]\tLoss: 99.003517\nTrain Epoch: 2 [19200/60000 (32%)]\tLoss: 98.754524\nTrain Epoch: 2 [20480/60000 (34%)]\tLoss: 102.079758\n",
      "Train Epoch: 2 [21760/60000 (36%)]\tLoss: 105.996300\nTrain Epoch: 2 [23040/60000 (38%)]\tLoss: 100.913635\n",
      "Train Epoch: 2 [24320/60000 (41%)]\tLoss: 103.751862\nTrain Epoch: 2 [25600/60000 (43%)]\tLoss: 106.991974\nTrain Epoch: 2 [26880/60000 (45%)]\tLoss: 100.501503\n",
      "Train Epoch: 2 [28160/60000 (47%)]\tLoss: 102.525787\nTrain Epoch: 2 [29440/60000 (49%)]\tLoss: 99.675415\nTrain Epoch: 2 [30720/60000 (51%)]\tLoss: 103.554749\n",
      "Train Epoch: 2 [32000/60000 (53%)]\tLoss: 104.321907\nTrain Epoch: 2 [33280/60000 (55%)]\tLoss: 98.567657\nTrain Epoch: 2 [34560/60000 (58%)]\tLoss: 100.694984\n",
      "Train Epoch: 2 [35840/60000 (60%)]\tLoss: 99.802505\nTrain Epoch: 2 [37120/60000 (62%)]\tLoss: 100.086197\nTrain Epoch: 2 [38400/60000 (64%)]\tLoss: 104.016724\n",
      "Train Epoch: 2 [39680/60000 (66%)]\tLoss: 103.080688\nTrain Epoch: 2 [40960/60000 (68%)]\tLoss: 104.024139\nTrain Epoch: 2 [42240/60000 (70%)]\tLoss: 100.525909\n",
      "Train Epoch: 2 [43520/60000 (72%)]\tLoss: 101.111488\nTrain Epoch: 2 [44800/60000 (75%)]\tLoss: 101.043427\nTrain Epoch: 2 [46080/60000 (77%)]\tLoss: 99.721756\n",
      "Train Epoch: 2 [47360/60000 (79%)]\tLoss: 100.247581\nTrain Epoch: 2 [48640/60000 (81%)]\tLoss: 102.243515\n",
      "Train Epoch: 2 [49920/60000 (83%)]\tLoss: 103.407379\nTrain Epoch: 2 [51200/60000 (85%)]\tLoss: 101.448151\nTrain Epoch: 2 [52480/60000 (87%)]\tLoss: 97.611923\n",
      "Train Epoch: 2 [53760/60000 (90%)]\tLoss: 101.575623\nTrain Epoch: 2 [55040/60000 (92%)]\tLoss: 101.332657\n",
      "Train Epoch: 2 [56320/60000 (94%)]\tLoss: 97.577888\nTrain Epoch: 2 [57600/60000 (96%)]\tLoss: 104.598022\n",
      "Train Epoch: 2 [58880/60000 (98%)]\tLoss: 100.951752\n",
      "====> Test set loss: 1.2469\n",
      "Train Epoch: 3 [0/60000 (0%)]\tLoss: 100.683502\nTrain Epoch: 3 [1280/60000 (2%)]\tLoss: 98.551758\nTrain Epoch: 3 [2560/60000 (4%)]\tLoss: 101.254196\n",
      "Train Epoch: 3 [3840/60000 (6%)]\tLoss: 101.735474\nTrain Epoch: 3 [5120/60000 (9%)]\tLoss: 101.773933\n",
      "Train Epoch: 3 [6400/60000 (11%)]\tLoss: 101.308960\nTrain Epoch: 3 [7680/60000 (13%)]\tLoss: 98.099770\n",
      "Train Epoch: 3 [8960/60000 (15%)]\tLoss: 102.477592\nTrain Epoch: 3 [10240/60000 (17%)]\tLoss: 97.455338\n",
      "Train Epoch: 3 [11520/60000 (19%)]\tLoss: 101.756920\nTrain Epoch: 3 [12800/60000 (21%)]\tLoss: 105.508362\n",
      "Train Epoch: 3 [14080/60000 (23%)]\tLoss: 102.584076\nTrain Epoch: 3 [15360/60000 (26%)]\tLoss: 98.250809\n",
      "Train Epoch: 3 [16640/60000 (28%)]\tLoss: 103.861008\nTrain Epoch: 3 [17920/60000 (30%)]\tLoss: 101.853683\n",
      "Train Epoch: 3 [19200/60000 (32%)]\tLoss: 100.878967\nTrain Epoch: 3 [20480/60000 (34%)]\tLoss: 99.644798\n",
      "Train Epoch: 3 [21760/60000 (36%)]\tLoss: 97.662491\nTrain Epoch: 3 [23040/60000 (38%)]\tLoss: 98.317520\n",
      "Train Epoch: 3 [24320/60000 (41%)]\tLoss: 101.750031\nTrain Epoch: 3 [25600/60000 (43%)]\tLoss: 99.171524\nTrain Epoch: 3 [26880/60000 (45%)]\tLoss: 102.126205\n",
      "Train Epoch: 3 [28160/60000 (47%)]\tLoss: 98.538383\nTrain Epoch: 3 [29440/60000 (49%)]\tLoss: 101.485359\nTrain Epoch: 3 [30720/60000 (51%)]\tLoss: 101.286148\n",
      "Train Epoch: 3 [32000/60000 (53%)]\tLoss: 99.671158\nTrain Epoch: 3 [33280/60000 (55%)]\tLoss: 104.817810\nTrain Epoch: 3 [34560/60000 (58%)]\tLoss: 104.414139\n",
      "Train Epoch: 3 [35840/60000 (60%)]\tLoss: 101.268875\nTrain Epoch: 3 [37120/60000 (62%)]\tLoss: 100.752647\nTrain Epoch: 3 [38400/60000 (64%)]\tLoss: 100.767059\n",
      "Train Epoch: 3 [39680/60000 (66%)]\tLoss: 101.781624\nTrain Epoch: 3 [40960/60000 (68%)]\tLoss: 103.274612\nTrain Epoch: 3 [42240/60000 (70%)]\tLoss: 100.251823\n",
      "Train Epoch: 3 [43520/60000 (72%)]\tLoss: 98.791969\nTrain Epoch: 3 [44800/60000 (75%)]\tLoss: 102.157791\n",
      "Train Epoch: 3 [46080/60000 (77%)]\tLoss: 103.771866\nTrain Epoch: 3 [47360/60000 (79%)]\tLoss: 97.052773\n",
      "Train Epoch: 3 [48640/60000 (81%)]\tLoss: 102.664665\nTrain Epoch: 3 [49920/60000 (83%)]\tLoss: 102.474518\n",
      "Train Epoch: 3 [51200/60000 (85%)]\tLoss: 100.111206\nTrain Epoch: 3 [52480/60000 (87%)]\tLoss: 103.587845\n",
      "Train Epoch: 3 [53760/60000 (90%)]\tLoss: 102.743515\nTrain Epoch: 3 [55040/60000 (92%)]\tLoss: 99.973404\n",
      "Train Epoch: 3 [56320/60000 (94%)]\tLoss: 101.837440\nTrain Epoch: 3 [57600/60000 (96%)]\tLoss: 100.029160\n",
      "Train Epoch: 3 [58880/60000 (98%)]\tLoss: 99.812851\n",
      "====> Test set loss: 1.2684\n",
      "Train Epoch: 4 [0/60000 (0%)]\tLoss: 103.903488\nTrain Epoch: 4 [1280/60000 (2%)]\tLoss: 105.168808\n",
      "Train Epoch: 4 [2560/60000 (4%)]\tLoss: 100.574669\nTrain Epoch: 4 [3840/60000 (6%)]\tLoss: 102.071320\n",
      "Train Epoch: 4 [5120/60000 (9%)]\tLoss: 102.824173\nTrain Epoch: 4 [6400/60000 (11%)]\tLoss: 103.745255\n",
      "Train Epoch: 4 [7680/60000 (13%)]\tLoss: 99.910378\nTrain Epoch: 4 [8960/60000 (15%)]\tLoss: 106.393341\n",
      "Train Epoch: 4 [10240/60000 (17%)]\tLoss: 102.363510\nTrain Epoch: 4 [11520/60000 (19%)]\tLoss: 100.914719\nTrain Epoch: 4 [12800/60000 (21%)]\tLoss: 100.677551\n",
      "Train Epoch: 4 [14080/60000 (23%)]\tLoss: 104.199074\nTrain Epoch: 4 [15360/60000 (26%)]\tLoss: 103.559845\nTrain Epoch: 4 [16640/60000 (28%)]\tLoss: 106.442001\n",
      "Train Epoch: 4 [17920/60000 (30%)]\tLoss: 104.781723\nTrain Epoch: 4 [19200/60000 (32%)]\tLoss: 100.617859\n",
      "Train Epoch: 4 [20480/60000 (34%)]\tLoss: 100.492928\nTrain Epoch: 4 [21760/60000 (36%)]\tLoss: 101.799149\n",
      "Train Epoch: 4 [23040/60000 (38%)]\tLoss: 103.024101\nTrain Epoch: 4 [24320/60000 (41%)]\tLoss: 102.052391\n",
      "Train Epoch: 4 [25600/60000 (43%)]\tLoss: 102.061317\nTrain Epoch: 4 [26880/60000 (45%)]\tLoss: 100.045654\nTrain Epoch: 4 [28160/60000 (47%)]\tLoss: 104.878532\n",
      "Train Epoch: 4 [29440/60000 (49%)]\tLoss: 103.391563\nTrain Epoch: 4 [30720/60000 (51%)]\tLoss: 97.852013\n",
      "Train Epoch: 4 [32000/60000 (53%)]\tLoss: 103.586060\nTrain Epoch: 4 [33280/60000 (55%)]\tLoss: 100.423973\nTrain Epoch: 4 [34560/60000 (58%)]\tLoss: 102.808533\n",
      "Train Epoch: 4 [35840/60000 (60%)]\tLoss: 102.408966\nTrain Epoch: 4 [37120/60000 (62%)]\tLoss: 102.053825\n",
      "Train Epoch: 4 [38400/60000 (64%)]\tLoss: 99.634247\nTrain Epoch: 4 [39680/60000 (66%)]\tLoss: 100.169197\n",
      "Train Epoch: 4 [40960/60000 (68%)]\tLoss: 100.920883\nTrain Epoch: 4 [42240/60000 (70%)]\tLoss: 102.775978\n",
      "Train Epoch: 4 [43520/60000 (72%)]\tLoss: 103.353539\nTrain Epoch: 4 [44800/60000 (75%)]\tLoss: 102.518860\n",
      "Train Epoch: 4 [46080/60000 (77%)]\tLoss: 101.123016\nTrain Epoch: 4 [47360/60000 (79%)]\tLoss: 97.034477\n",
      "Train Epoch: 4 [48640/60000 (81%)]\tLoss: 98.427887\nTrain Epoch: 4 [49920/60000 (83%)]\tLoss: 102.630676\n",
      "Train Epoch: 4 [51200/60000 (85%)]\tLoss: 100.504036\nTrain Epoch: 4 [52480/60000 (87%)]\tLoss: 104.526505\n",
      "Train Epoch: 4 [53760/60000 (90%)]\tLoss: 100.351555\nTrain Epoch: 4 [55040/60000 (92%)]\tLoss: 103.243362\nTrain Epoch: 4 [56320/60000 (94%)]\tLoss: 103.754951\n",
      "Train Epoch: 4 [57600/60000 (96%)]\tLoss: 102.997749\nTrain Epoch: 4 [58880/60000 (98%)]\tLoss: 101.035507\n",
      "====> Test set loss: 1.2948\n",
      "Train Epoch: 5 [0/60000 (0%)]\tLoss: 101.037460\nTrain Epoch: 5 [1280/60000 (2%)]\tLoss: 105.448090\n",
      "Train Epoch: 5 [2560/60000 (4%)]\tLoss: 100.426849\nTrain Epoch: 5 [3840/60000 (6%)]\tLoss: 99.277153\nTrain Epoch: 5 [5120/60000 (9%)]\tLoss: 99.073242\n",
      "Train Epoch: 5 [6400/60000 (11%)]\tLoss: 105.294456\nTrain Epoch: 5 [7680/60000 (13%)]\tLoss: 105.384659\nTrain Epoch: 5 [8960/60000 (15%)]\tLoss: 103.248558\n",
      "Train Epoch: 5 [10240/60000 (17%)]\tLoss: 101.114456\nTrain Epoch: 5 [11520/60000 (19%)]\tLoss: 99.686150\n",
      "Train Epoch: 5 [12800/60000 (21%)]\tLoss: 103.260544\nTrain Epoch: 5 [14080/60000 (23%)]\tLoss: 100.166786\n",
      "Train Epoch: 5 [15360/60000 (26%)]\tLoss: 105.330338\nTrain Epoch: 5 [16640/60000 (28%)]\tLoss: 98.102982\nTrain Epoch: 5 [17920/60000 (30%)]\tLoss: 101.898270\n",
      "Train Epoch: 5 [19200/60000 (32%)]\tLoss: 103.129906\nTrain Epoch: 5 [20480/60000 (34%)]\tLoss: 102.270462\n",
      "Train Epoch: 5 [21760/60000 (36%)]\tLoss: 99.638611\nTrain Epoch: 5 [23040/60000 (38%)]\tLoss: 103.988708\n",
      "Train Epoch: 5 [24320/60000 (41%)]\tLoss: 101.017258\nTrain Epoch: 5 [25600/60000 (43%)]\tLoss: 103.925461\n",
      "Train Epoch: 5 [26880/60000 (45%)]\tLoss: 101.931587\nTrain Epoch: 5 [28160/60000 (47%)]\tLoss: 101.333755\nTrain Epoch: 5 [29440/60000 (49%)]\tLoss: 103.059769\n",
      "Train Epoch: 5 [30720/60000 (51%)]\tLoss: 99.902771\nTrain Epoch: 5 [32000/60000 (53%)]\tLoss: 101.344467\n",
      "Train Epoch: 5 [33280/60000 (55%)]\tLoss: 102.575165\nTrain Epoch: 5 [34560/60000 (58%)]\tLoss: 102.776672\nTrain Epoch: 5 [35840/60000 (60%)]\tLoss: 103.028061\n",
      "Train Epoch: 5 [37120/60000 (62%)]\tLoss: 105.110420\nTrain Epoch: 5 [38400/60000 (64%)]\tLoss: 102.427116\nTrain Epoch: 5 [39680/60000 (66%)]\tLoss: 98.899750\n",
      "Train Epoch: 5 [40960/60000 (68%)]\tLoss: 101.196671\nTrain Epoch: 5 [42240/60000 (70%)]\tLoss: 98.589020\nTrain Epoch: 5 [43520/60000 (72%)]\tLoss: 101.405991\n",
      "Train Epoch: 5 [44800/60000 (75%)]\tLoss: 103.476906\nTrain Epoch: 5 [46080/60000 (77%)]\tLoss: 100.406662\nTrain Epoch: 5 [47360/60000 (79%)]\tLoss: 102.008423\n",
      "Train Epoch: 5 [48640/60000 (81%)]\tLoss: 99.462433\nTrain Epoch: 5 [49920/60000 (83%)]\tLoss: 100.344002\n",
      "Train Epoch: 5 [51200/60000 (85%)]\tLoss: 101.672791\nTrain Epoch: 5 [52480/60000 (87%)]\tLoss: 100.490868\nTrain Epoch: 5 [53760/60000 (90%)]\tLoss: 97.858643\n",
      "Train Epoch: 5 [55040/60000 (92%)]\tLoss: 103.512985\nTrain Epoch: 5 [56320/60000 (94%)]\tLoss: 100.127350\nTrain Epoch: 5 [57600/60000 (96%)]\tLoss: 102.148438\n",
      "Train Epoch: 5 [58880/60000 (98%)]\tLoss: 103.011047\n",
      "====> Test set loss: 1.3510\n",
      "Train Epoch: 6 [0/60000 (0%)]\tLoss: 100.783173\nTrain Epoch: 6 [1280/60000 (2%)]\tLoss: 98.067505\nTrain Epoch: 6 [2560/60000 (4%)]\tLoss: 101.206772\n",
      "Train Epoch: 6 [3840/60000 (6%)]\tLoss: 101.779305\nTrain Epoch: 6 [5120/60000 (9%)]\tLoss: 99.473137\nTrain Epoch: 6 [6400/60000 (11%)]\tLoss: 101.654556\n",
      "Train Epoch: 6 [7680/60000 (13%)]\tLoss: 99.105515\nTrain Epoch: 6 [8960/60000 (15%)]\tLoss: 100.474251\n",
      "Train Epoch: 6 [10240/60000 (17%)]\tLoss: 100.018433\nTrain Epoch: 6 [11520/60000 (19%)]\tLoss: 102.157440\nTrain Epoch: 6 [12800/60000 (21%)]\tLoss: 101.475082\n",
      "Train Epoch: 6 [14080/60000 (23%)]\tLoss: 103.009697\nTrain Epoch: 6 [15360/60000 (26%)]\tLoss: 102.731918\nTrain Epoch: 6 [16640/60000 (28%)]\tLoss: 101.516769\n",
      "Train Epoch: 6 [17920/60000 (30%)]\tLoss: 100.291481\nTrain Epoch: 6 [19200/60000 (32%)]\tLoss: 104.636108\nTrain Epoch: 6 [20480/60000 (34%)]\tLoss: 99.001709\n",
      "Train Epoch: 6 [21760/60000 (36%)]\tLoss: 99.808456\nTrain Epoch: 6 [23040/60000 (38%)]\tLoss: 98.548981\nTrain Epoch: 6 [24320/60000 (41%)]\tLoss: 98.721741\n",
      "Train Epoch: 6 [25600/60000 (43%)]\tLoss: 102.076645\nTrain Epoch: 6 [26880/60000 (45%)]\tLoss: 101.354744\nTrain Epoch: 6 [28160/60000 (47%)]\tLoss: 100.539917\n",
      "Train Epoch: 6 [29440/60000 (49%)]\tLoss: 98.016083\nTrain Epoch: 6 [30720/60000 (51%)]\tLoss: 101.617767\nTrain Epoch: 6 [32000/60000 (53%)]\tLoss: 101.609009\n",
      "Train Epoch: 6 [33280/60000 (55%)]\tLoss: 101.532722\nTrain Epoch: 6 [34560/60000 (58%)]\tLoss: 99.114700\n",
      "Train Epoch: 6 [35840/60000 (60%)]\tLoss: 103.615776\nTrain Epoch: 6 [37120/60000 (62%)]\tLoss: 103.362015\n",
      "Train Epoch: 6 [38400/60000 (64%)]\tLoss: 97.648514\nTrain Epoch: 6 [39680/60000 (66%)]\tLoss: 101.858528\nTrain Epoch: 6 [40960/60000 (68%)]\tLoss: 99.006157\n",
      "Train Epoch: 6 [42240/60000 (70%)]\tLoss: 99.629944\nTrain Epoch: 6 [43520/60000 (72%)]\tLoss: 102.705200\n",
      "Train Epoch: 6 [44800/60000 (75%)]\tLoss: 97.318954\nTrain Epoch: 6 [46080/60000 (77%)]\tLoss: 101.070290\n",
      "Train Epoch: 6 [47360/60000 (79%)]\tLoss: 103.647285\nTrain Epoch: 6 [48640/60000 (81%)]\tLoss: 98.976227\n",
      "Train Epoch: 6 [49920/60000 (83%)]\tLoss: 99.153381\nTrain Epoch: 6 [51200/60000 (85%)]\tLoss: 102.068710\nTrain Epoch: 6 [52480/60000 (87%)]\tLoss: 100.551300\n",
      "Train Epoch: 6 [53760/60000 (90%)]\tLoss: 101.662140\nTrain Epoch: 6 [55040/60000 (92%)]\tLoss: 98.427979\n",
      "Train Epoch: 6 [56320/60000 (94%)]\tLoss: 100.701256\nTrain Epoch: 6 [57600/60000 (96%)]\tLoss: 104.665161\n",
      "Train Epoch: 6 [58880/60000 (98%)]\tLoss: 102.938545\n",
      "====> Test set loss: 1.3452\n",
      "Train Epoch: 7 [0/60000 (0%)]\tLoss: 101.489761\nTrain Epoch: 7 [1280/60000 (2%)]\tLoss: 103.266800\nTrain Epoch: 7 [2560/60000 (4%)]\tLoss: 106.069519\n",
      "Train Epoch: 7 [3840/60000 (6%)]\tLoss: 102.873688\nTrain Epoch: 7 [5120/60000 (9%)]\tLoss: 98.377632\nTrain Epoch: 7 [6400/60000 (11%)]\tLoss: 97.443817\n",
      "Train Epoch: 7 [7680/60000 (13%)]\tLoss: 102.319717\nTrain Epoch: 7 [8960/60000 (15%)]\tLoss: 99.739365\n",
      "Train Epoch: 7 [10240/60000 (17%)]\tLoss: 102.711517\nTrain Epoch: 7 [11520/60000 (19%)]\tLoss: 101.220436\nTrain Epoch: 7 [12800/60000 (21%)]\tLoss: 97.632523\n",
      "Train Epoch: 7 [14080/60000 (23%)]\tLoss: 100.467773\nTrain Epoch: 7 [15360/60000 (26%)]\tLoss: 98.676064\nTrain Epoch: 7 [16640/60000 (28%)]\tLoss: 97.471451\n",
      "Train Epoch: 7 [17920/60000 (30%)]\tLoss: 98.770187\nTrain Epoch: 7 [19200/60000 (32%)]\tLoss: 102.841797\nTrain Epoch: 7 [20480/60000 (34%)]\tLoss: 98.961319\n",
      "Train Epoch: 7 [21760/60000 (36%)]\tLoss: 100.087555\nTrain Epoch: 7 [23040/60000 (38%)]\tLoss: 99.336594\nTrain Epoch: 7 [24320/60000 (41%)]\tLoss: 101.784485\n",
      "Train Epoch: 7 [25600/60000 (43%)]\tLoss: 102.961197\nTrain Epoch: 7 [26880/60000 (45%)]\tLoss: 102.620605\nTrain Epoch: 7 [28160/60000 (47%)]\tLoss: 102.856117\n",
      "Train Epoch: 7 [29440/60000 (49%)]\tLoss: 98.472588\nTrain Epoch: 7 [30720/60000 (51%)]\tLoss: 97.471428\nTrain Epoch: 7 [32000/60000 (53%)]\tLoss: 101.237129\n",
      "Train Epoch: 7 [33280/60000 (55%)]\tLoss: 103.252762\nTrain Epoch: 7 [34560/60000 (58%)]\tLoss: 99.983238\nTrain Epoch: 7 [35840/60000 (60%)]\tLoss: 101.131523\n",
      "Train Epoch: 7 [37120/60000 (62%)]\tLoss: 102.111244\nTrain Epoch: 7 [38400/60000 (64%)]\tLoss: 99.661034\n",
      "Train Epoch: 7 [39680/60000 (66%)]\tLoss: 100.708420\nTrain Epoch: 7 [40960/60000 (68%)]\tLoss: 101.792404\n",
      "Train Epoch: 7 [42240/60000 (70%)]\tLoss: 100.530060\nTrain Epoch: 7 [43520/60000 (72%)]\tLoss: 97.989281\n",
      "Train Epoch: 7 [44800/60000 (75%)]\tLoss: 101.081055\nTrain Epoch: 7 [46080/60000 (77%)]\tLoss: 102.557526\n",
      "Train Epoch: 7 [47360/60000 (79%)]\tLoss: 99.972923\nTrain Epoch: 7 [48640/60000 (81%)]\tLoss: 99.974792\nTrain Epoch: 7 [49920/60000 (83%)]\tLoss: 101.581436\n",
      "Train Epoch: 7 [51200/60000 (85%)]\tLoss: 103.453903\nTrain Epoch: 7 [52480/60000 (87%)]\tLoss: 101.781616\nTrain Epoch: 7 [53760/60000 (90%)]\tLoss: 102.522781\n",
      "Train Epoch: 7 [55040/60000 (92%)]\tLoss: 103.214874\nTrain Epoch: 7 [56320/60000 (94%)]\tLoss: 104.775772\nTrain Epoch: 7 [57600/60000 (96%)]\tLoss: 99.599777\n",
      "Train Epoch: 7 [58880/60000 (98%)]\tLoss: 97.262344\n",
      "====> Test set loss: 1.3468\n",
      "Train Epoch: 8 [0/60000 (0%)]\tLoss: 101.208832\nTrain Epoch: 8 [1280/60000 (2%)]\tLoss: 99.961708\nTrain Epoch: 8 [2560/60000 (4%)]\tLoss: 106.799301\n",
      "Train Epoch: 8 [3840/60000 (6%)]\tLoss: 98.449043\nTrain Epoch: 8 [5120/60000 (9%)]\tLoss: 99.457397\nTrain Epoch: 8 [6400/60000 (11%)]\tLoss: 106.103119\n",
      "Train Epoch: 8 [7680/60000 (13%)]\tLoss: 99.077072\nTrain Epoch: 8 [8960/60000 (15%)]\tLoss: 99.970932\n",
      "Train Epoch: 8 [10240/60000 (17%)]\tLoss: 101.620392\nTrain Epoch: 8 [11520/60000 (19%)]\tLoss: 96.298309\nTrain Epoch: 8 [12800/60000 (21%)]\tLoss: 100.299576\n",
      "Train Epoch: 8 [14080/60000 (23%)]\tLoss: 102.641510\nTrain Epoch: 8 [15360/60000 (26%)]\tLoss: 101.810822\nTrain Epoch: 8 [16640/60000 (28%)]\tLoss: 100.849777\n",
      "Train Epoch: 8 [17920/60000 (30%)]\tLoss: 103.924622\nTrain Epoch: 8 [19200/60000 (32%)]\tLoss: 99.146500\n",
      "Train Epoch: 8 [20480/60000 (34%)]\tLoss: 98.366089\nTrain Epoch: 8 [21760/60000 (36%)]\tLoss: 103.142693\n",
      "Train Epoch: 8 [23040/60000 (38%)]\tLoss: 103.637794\nTrain Epoch: 8 [24320/60000 (41%)]\tLoss: 101.905167\n",
      "Train Epoch: 8 [25600/60000 (43%)]\tLoss: 100.014191\nTrain Epoch: 8 [26880/60000 (45%)]\tLoss: 98.372292\nTrain Epoch: 8 [28160/60000 (47%)]\tLoss: 103.157433\n",
      "Train Epoch: 8 [29440/60000 (49%)]\tLoss: 99.424385\nTrain Epoch: 8 [30720/60000 (51%)]\tLoss: 101.037735\n",
      "Train Epoch: 8 [32000/60000 (53%)]\tLoss: 100.431793\nTrain Epoch: 8 [33280/60000 (55%)]\tLoss: 97.162285\n",
      "Train Epoch: 8 [34560/60000 (58%)]\tLoss: 102.156387\nTrain Epoch: 8 [35840/60000 (60%)]\tLoss: 98.520035\n",
      "Train Epoch: 8 [37120/60000 (62%)]\tLoss: 102.408928\nTrain Epoch: 8 [38400/60000 (64%)]\tLoss: 103.499748\n",
      "Train Epoch: 8 [39680/60000 (66%)]\tLoss: 102.807571\nTrain Epoch: 8 [40960/60000 (68%)]\tLoss: 102.635284\n",
      "Train Epoch: 8 [42240/60000 (70%)]\tLoss: 94.773605\nTrain Epoch: 8 [43520/60000 (72%)]\tLoss: 102.055649\nTrain Epoch: 8 [44800/60000 (75%)]\tLoss: 104.993690\n",
      "Train Epoch: 8 [46080/60000 (77%)]\tLoss: 101.071548\nTrain Epoch: 8 [47360/60000 (79%)]\tLoss: 104.575783\nTrain Epoch: 8 [48640/60000 (81%)]\tLoss: 100.200912\n",
      "Train Epoch: 8 [49920/60000 (83%)]\tLoss: 101.506126\nTrain Epoch: 8 [51200/60000 (85%)]\tLoss: 100.169029\nTrain Epoch: 8 [52480/60000 (87%)]\tLoss: 98.400635\n",
      "Train Epoch: 8 [53760/60000 (90%)]\tLoss: 101.884315\nTrain Epoch: 8 [55040/60000 (92%)]\tLoss: 110.782364\nTrain Epoch: 8 [56320/60000 (94%)]\tLoss: 98.669968\n",
      "Train Epoch: 8 [57600/60000 (96%)]\tLoss: 101.572563\nTrain Epoch: 8 [58880/60000 (98%)]\tLoss: 102.341415\n",
      "====> Test set loss: 1.3081\n",
      "Train Epoch: 9 [0/60000 (0%)]\tLoss: 101.711609\nTrain Epoch: 9 [1280/60000 (2%)]\tLoss: 102.994965\nTrain Epoch: 9 [2560/60000 (4%)]\tLoss: 99.433350\n",
      "Train Epoch: 9 [3840/60000 (6%)]\tLoss: 93.421669\nTrain Epoch: 9 [5120/60000 (9%)]\tLoss: 107.303749\nTrain Epoch: 9 [6400/60000 (11%)]\tLoss: 100.226868\n",
      "Train Epoch: 9 [7680/60000 (13%)]\tLoss: 101.526627\nTrain Epoch: 9 [8960/60000 (15%)]\tLoss: 96.957710\nTrain Epoch: 9 [10240/60000 (17%)]\tLoss: 98.694626\n",
      "Train Epoch: 9 [11520/60000 (19%)]\tLoss: 104.630241\nTrain Epoch: 9 [12800/60000 (21%)]\tLoss: 98.850403\n",
      "Train Epoch: 9 [14080/60000 (23%)]\tLoss: 102.569954\nTrain Epoch: 9 [15360/60000 (26%)]\tLoss: 100.701813\nTrain Epoch: 9 [16640/60000 (28%)]\tLoss: 99.863373\n",
      "Train Epoch: 9 [17920/60000 (30%)]\tLoss: 100.170532\nTrain Epoch: 9 [19200/60000 (32%)]\tLoss: 98.761047\nTrain Epoch: 9 [20480/60000 (34%)]\tLoss: 101.591125\n",
      "Train Epoch: 9 [21760/60000 (36%)]\tLoss: 102.516815\nTrain Epoch: 9 [23040/60000 (38%)]\tLoss: 95.675629\nTrain Epoch: 9 [24320/60000 (41%)]\tLoss: 100.910690\n",
      "Train Epoch: 9 [25600/60000 (43%)]\tLoss: 101.522537\nTrain Epoch: 9 [26880/60000 (45%)]\tLoss: 101.150253\n",
      "Train Epoch: 9 [28160/60000 (47%)]\tLoss: 97.592438\nTrain Epoch: 9 [29440/60000 (49%)]\tLoss: 102.631050\nTrain Epoch: 9 [30720/60000 (51%)]\tLoss: 102.499969\n",
      "Train Epoch: 9 [32000/60000 (53%)]\tLoss: 100.899231\nTrain Epoch: 9 [33280/60000 (55%)]\tLoss: 100.144066\nTrain Epoch: 9 [34560/60000 (58%)]\tLoss: 103.121124\n",
      "Train Epoch: 9 [35840/60000 (60%)]\tLoss: 99.604630\nTrain Epoch: 9 [37120/60000 (62%)]\tLoss: 101.513542\n",
      "Train Epoch: 9 [38400/60000 (64%)]\tLoss: 103.762558\nTrain Epoch: 9 [39680/60000 (66%)]\tLoss: 99.032455\nTrain Epoch: 9 [40960/60000 (68%)]\tLoss: 103.720764\n",
      "Train Epoch: 9 [42240/60000 (70%)]\tLoss: 102.365234\nTrain Epoch: 9 [43520/60000 (72%)]\tLoss: 98.122337\n",
      "Train Epoch: 9 [44800/60000 (75%)]\tLoss: 100.150536\nTrain Epoch: 9 [46080/60000 (77%)]\tLoss: 101.098885\n",
      "Train Epoch: 9 [47360/60000 (79%)]\tLoss: 98.588074\nTrain Epoch: 9 [48640/60000 (81%)]\tLoss: 103.550926\nTrain Epoch: 9 [49920/60000 (83%)]\tLoss: 101.266006\n",
      "Train Epoch: 9 [51200/60000 (85%)]\tLoss: 99.321159\nTrain Epoch: 9 [52480/60000 (87%)]\tLoss: 102.385971\n",
      "Train Epoch: 9 [53760/60000 (90%)]\tLoss: 101.311310\nTrain Epoch: 9 [55040/60000 (92%)]\tLoss: 98.300117\n",
      "Train Epoch: 9 [56320/60000 (94%)]\tLoss: 101.634377\nTrain Epoch: 9 [57600/60000 (96%)]\tLoss: 103.719177\n",
      "Train Epoch: 9 [58880/60000 (98%)]\tLoss: 102.817863\n",
      "====> Test set loss: 1.3318\n",
      "Train Epoch: 10 [0/60000 (0%)]\tLoss: 100.119965\nTrain Epoch: 10 [1280/60000 (2%)]\tLoss: 101.481178\nTrain Epoch: 10 [2560/60000 (4%)]\tLoss: 100.867287\n",
      "Train Epoch: 10 [3840/60000 (6%)]\tLoss: 96.626801\nTrain Epoch: 10 [5120/60000 (9%)]\tLoss: 103.032532\nTrain Epoch: 10 [6400/60000 (11%)]\tLoss: 102.595001\n",
      "Train Epoch: 10 [7680/60000 (13%)]\tLoss: 101.973663\nTrain Epoch: 10 [8960/60000 (15%)]\tLoss: 103.151001\nTrain Epoch: 10 [10240/60000 (17%)]\tLoss: 98.961105\n",
      "Train Epoch: 10 [11520/60000 (19%)]\tLoss: 102.294556\nTrain Epoch: 10 [12800/60000 (21%)]\tLoss: 100.360939\nTrain Epoch: 10 [14080/60000 (23%)]\tLoss: 100.516228\n",
      "Train Epoch: 10 [15360/60000 (26%)]\tLoss: 99.987152\nTrain Epoch: 10 [16640/60000 (28%)]\tLoss: 102.750298\n",
      "Train Epoch: 10 [17920/60000 (30%)]\tLoss: 102.784195\nTrain Epoch: 10 [19200/60000 (32%)]\tLoss: 102.509354\nTrain Epoch: 10 [20480/60000 (34%)]\tLoss: 100.369469\n",
      "Train Epoch: 10 [21760/60000 (36%)]\tLoss: 101.738052\nTrain Epoch: 10 [23040/60000 (38%)]\tLoss: 99.551086\n",
      "Train Epoch: 10 [24320/60000 (41%)]\tLoss: 100.269577\nTrain Epoch: 10 [25600/60000 (43%)]\tLoss: 102.096840\n",
      "Train Epoch: 10 [26880/60000 (45%)]\tLoss: 101.618301\nTrain Epoch: 10 [28160/60000 (47%)]\tLoss: 99.066521\n",
      "Train Epoch: 10 [29440/60000 (49%)]\tLoss: 97.667511\nTrain Epoch: 10 [30720/60000 (51%)]\tLoss: 105.238098\n",
      "Train Epoch: 10 [32000/60000 (53%)]\tLoss: 99.786926\nTrain Epoch: 10 [33280/60000 (55%)]\tLoss: 103.192825\nTrain Epoch: 10 [34560/60000 (58%)]\tLoss: 103.596207\n",
      "Train Epoch: 10 [35840/60000 (60%)]\tLoss: 100.238976\nTrain Epoch: 10 [37120/60000 (62%)]\tLoss: 98.645416\nTrain Epoch: 10 [38400/60000 (64%)]\tLoss: 103.341003\n",
      "Train Epoch: 10 [39680/60000 (66%)]\tLoss: 100.320480\nTrain Epoch: 10 [40960/60000 (68%)]\tLoss: 100.929787\nTrain Epoch: 10 [42240/60000 (70%)]\tLoss: 106.177025\n",
      "Train Epoch: 10 [43520/60000 (72%)]\tLoss: 103.867661\nTrain Epoch: 10 [44800/60000 (75%)]\tLoss: 104.391006\n",
      "Train Epoch: 10 [46080/60000 (77%)]\tLoss: 102.420021\nTrain Epoch: 10 [47360/60000 (79%)]\tLoss: 103.698929\nTrain Epoch: 10 [48640/60000 (81%)]\tLoss: 101.356102\n",
      "Train Epoch: 10 [49920/60000 (83%)]\tLoss: 103.358612\nTrain Epoch: 10 [51200/60000 (85%)]\tLoss: 106.006577\n",
      "Train Epoch: 10 [52480/60000 (87%)]\tLoss: 100.911858\nTrain Epoch: 10 [53760/60000 (90%)]\tLoss: 96.852379\nTrain Epoch: 10 [55040/60000 (92%)]\tLoss: 102.368011\n",
      "Train Epoch: 10 [56320/60000 (94%)]\tLoss: 100.734093\nTrain Epoch: 10 [57600/60000 (96%)]\tLoss: 105.325363\n",
      "Train Epoch: 10 [58880/60000 (98%)]\tLoss: 102.265503\n",
      "====> Test set loss: 1.2602\n",
      "Train Epoch: 11 [0/60000 (0%)]\tLoss: 101.273254\nTrain Epoch: 11 [1280/60000 (2%)]\tLoss: 101.339439\nTrain Epoch: 11 [2560/60000 (4%)]\tLoss: 104.789810\n",
      "Train Epoch: 11 [3840/60000 (6%)]\tLoss: 100.313614\nTrain Epoch: 11 [5120/60000 (9%)]\tLoss: 96.105515\nTrain Epoch: 11 [6400/60000 (11%)]\tLoss: 102.365112\n",
      "Train Epoch: 11 [7680/60000 (13%)]\tLoss: 104.700783\nTrain Epoch: 11 [8960/60000 (15%)]\tLoss: 102.453003\n",
      "Train Epoch: 11 [10240/60000 (17%)]\tLoss: 99.880600\nTrain Epoch: 11 [11520/60000 (19%)]\tLoss: 100.446823\nTrain Epoch: 11 [12800/60000 (21%)]\tLoss: 105.112289\n",
      "Train Epoch: 11 [14080/60000 (23%)]\tLoss: 103.654541\nTrain Epoch: 11 [15360/60000 (26%)]\tLoss: 101.079422\nTrain Epoch: 11 [16640/60000 (28%)]\tLoss: 101.492470\n",
      "Train Epoch: 11 [17920/60000 (30%)]\tLoss: 102.167221\nTrain Epoch: 11 [19200/60000 (32%)]\tLoss: 100.101776\nTrain Epoch: 11 [20480/60000 (34%)]\tLoss: 100.050781\n",
      "Train Epoch: 11 [21760/60000 (36%)]\tLoss: 101.293976\nTrain Epoch: 11 [23040/60000 (38%)]\tLoss: 104.496582\nTrain Epoch: 11 [24320/60000 (41%)]\tLoss: 104.059837\n",
      "Train Epoch: 11 [25600/60000 (43%)]\tLoss: 100.317497\nTrain Epoch: 11 [26880/60000 (45%)]\tLoss: 103.380058\n",
      "Train Epoch: 11 [28160/60000 (47%)]\tLoss: 102.228638\nTrain Epoch: 11 [29440/60000 (49%)]\tLoss: 100.531006\n",
      "Train Epoch: 11 [30720/60000 (51%)]\tLoss: 99.940231\nTrain Epoch: 11 [32000/60000 (53%)]\tLoss: 99.653244\nTrain Epoch: 11 [33280/60000 (55%)]\tLoss: 103.319496\n",
      "Train Epoch: 11 [34560/60000 (58%)]\tLoss: 98.226051\nTrain Epoch: 11 [35840/60000 (60%)]\tLoss: 104.699783\nTrain Epoch: 11 [37120/60000 (62%)]\tLoss: 101.838074\n",
      "Train Epoch: 11 [38400/60000 (64%)]\tLoss: 101.291382\nTrain Epoch: 11 [39680/60000 (66%)]\tLoss: 100.425941\nTrain Epoch: 11 [40960/60000 (68%)]\tLoss: 98.234039\n",
      "Train Epoch: 11 [42240/60000 (70%)]\tLoss: 100.130249\nTrain Epoch: 11 [43520/60000 (72%)]\tLoss: 103.374191\nTrain Epoch: 11 [44800/60000 (75%)]\tLoss: 101.069954\n",
      "Train Epoch: 11 [46080/60000 (77%)]\tLoss: 103.408096\nTrain Epoch: 11 [47360/60000 (79%)]\tLoss: 103.729401\nTrain Epoch: 11 [48640/60000 (81%)]\tLoss: 102.674362\n",
      "Train Epoch: 11 [49920/60000 (83%)]\tLoss: 103.504158\nTrain Epoch: 11 [51200/60000 (85%)]\tLoss: 100.823074\nTrain Epoch: 11 [52480/60000 (87%)]\tLoss: 101.297798\n",
      "Train Epoch: 11 [53760/60000 (90%)]\tLoss: 101.244446\nTrain Epoch: 11 [55040/60000 (92%)]\tLoss: 96.142471\nTrain Epoch: 11 [56320/60000 (94%)]\tLoss: 101.968643\n",
      "Train Epoch: 11 [57600/60000 (96%)]\tLoss: 93.908463\nTrain Epoch: 11 [58880/60000 (98%)]\tLoss: 100.554581\n",
      "====> Test set loss: 1.3150\n",
      "Train Epoch: 12 [0/60000 (0%)]\tLoss: 99.310425\nTrain Epoch: 12 [1280/60000 (2%)]\tLoss: 101.688972\nTrain Epoch: 12 [2560/60000 (4%)]\tLoss: 104.021698\n",
      "Train Epoch: 12 [3840/60000 (6%)]\tLoss: 100.397881\nTrain Epoch: 12 [5120/60000 (9%)]\tLoss: 103.103729\nTrain Epoch: 12 [6400/60000 (11%)]\tLoss: 102.879822\n",
      "Train Epoch: 12 [7680/60000 (13%)]\tLoss: 100.967209\nTrain Epoch: 12 [8960/60000 (15%)]\tLoss: 102.244827\nTrain Epoch: 12 [10240/60000 (17%)]\tLoss: 102.897980\n",
      "Train Epoch: 12 [11520/60000 (19%)]\tLoss: 98.964722\nTrain Epoch: 12 [12800/60000 (21%)]\tLoss: 98.762306\nTrain Epoch: 12 [14080/60000 (23%)]\tLoss: 105.470154\n",
      "Train Epoch: 12 [15360/60000 (26%)]\tLoss: 106.610939\nTrain Epoch: 12 [16640/60000 (28%)]\tLoss: 98.966606\nTrain Epoch: 12 [17920/60000 (30%)]\tLoss: 100.413361\n",
      "Train Epoch: 12 [19200/60000 (32%)]\tLoss: 97.050362\nTrain Epoch: 12 [20480/60000 (34%)]\tLoss: 105.640717\n",
      "Train Epoch: 12 [21760/60000 (36%)]\tLoss: 103.026237\nTrain Epoch: 12 [23040/60000 (38%)]\tLoss: 101.470001\n",
      "Train Epoch: 12 [24320/60000 (41%)]\tLoss: 102.683853\nTrain Epoch: 12 [25600/60000 (43%)]\tLoss: 100.515335\nTrain Epoch: 12 [26880/60000 (45%)]\tLoss: 102.750107\n",
      "Train Epoch: 12 [28160/60000 (47%)]\tLoss: 102.147919\nTrain Epoch: 12 [29440/60000 (49%)]\tLoss: 100.929672\nTrain Epoch: 12 [30720/60000 (51%)]\tLoss: 104.006866\n",
      "Train Epoch: 12 [32000/60000 (53%)]\tLoss: 100.308273\nTrain Epoch: 12 [33280/60000 (55%)]\tLoss: 103.708481\nTrain Epoch: 12 [34560/60000 (58%)]\tLoss: 101.343300\n",
      "Train Epoch: 12 [35840/60000 (60%)]\tLoss: 98.443840\nTrain Epoch: 12 [37120/60000 (62%)]\tLoss: 102.694534\nTrain Epoch: 12 [38400/60000 (64%)]\tLoss: 103.042191\n",
      "Train Epoch: 12 [39680/60000 (66%)]\tLoss: 101.772919\nTrain Epoch: 12 [40960/60000 (68%)]\tLoss: 101.803528\nTrain Epoch: 12 [42240/60000 (70%)]\tLoss: 102.774063\n",
      "Train Epoch: 12 [43520/60000 (72%)]\tLoss: 97.097069\nTrain Epoch: 12 [44800/60000 (75%)]\tLoss: 102.135590\n",
      "Train Epoch: 12 [46080/60000 (77%)]\tLoss: 103.540894\nTrain Epoch: 12 [47360/60000 (79%)]\tLoss: 106.025642\n",
      "Train Epoch: 12 [48640/60000 (81%)]\tLoss: 101.418427\nTrain Epoch: 12 [49920/60000 (83%)]\tLoss: 100.455559\nTrain Epoch: 12 [51200/60000 (85%)]\tLoss: 96.719154\n",
      "Train Epoch: 12 [52480/60000 (87%)]\tLoss: 101.050781\nTrain Epoch: 12 [53760/60000 (90%)]\tLoss: 104.378365\n",
      "Train Epoch: 12 [55040/60000 (92%)]\tLoss: 104.500687\nTrain Epoch: 12 [56320/60000 (94%)]\tLoss: 98.645210\n",
      "Train Epoch: 12 [57600/60000 (96%)]\tLoss: 105.414307\nTrain Epoch: 12 [58880/60000 (98%)]\tLoss: 100.361084\n",
      "====> Test set loss: 1.2553\n",
      "Train Epoch: 13 [0/60000 (0%)]\tLoss: 97.373352\nTrain Epoch: 13 [1280/60000 (2%)]\tLoss: 99.548660\nTrain Epoch: 13 [2560/60000 (4%)]\tLoss: 103.371185\n",
      "Train Epoch: 13 [3840/60000 (6%)]\tLoss: 101.908813\nTrain Epoch: 13 [5120/60000 (9%)]\tLoss: 102.152359\n",
      "Train Epoch: 13 [6400/60000 (11%)]\tLoss: 99.367508\nTrain Epoch: 13 [7680/60000 (13%)]\tLoss: 104.159264\nTrain Epoch: 13 [8960/60000 (15%)]\tLoss: 98.578323\n",
      "Train Epoch: 13 [10240/60000 (17%)]\tLoss: 102.284760\nTrain Epoch: 13 [11520/60000 (19%)]\tLoss: 98.348915\nTrain Epoch: 13 [12800/60000 (21%)]\tLoss: 101.323792\n",
      "Train Epoch: 13 [14080/60000 (23%)]\tLoss: 103.574310\nTrain Epoch: 13 [15360/60000 (26%)]\tLoss: 97.489395\n",
      "Train Epoch: 13 [16640/60000 (28%)]\tLoss: 102.250610\nTrain Epoch: 13 [17920/60000 (30%)]\tLoss: 101.585182\n",
      "Train Epoch: 13 [19200/60000 (32%)]\tLoss: 102.897552\nTrain Epoch: 13 [20480/60000 (34%)]\tLoss: 100.350395\nTrain Epoch: 13 [21760/60000 (36%)]\tLoss: 101.930206\n",
      "Train Epoch: 13 [23040/60000 (38%)]\tLoss: 98.262314\nTrain Epoch: 13 [24320/60000 (41%)]\tLoss: 98.734894\nTrain Epoch: 13 [25600/60000 (43%)]\tLoss: 103.731270\n",
      "Train Epoch: 13 [26880/60000 (45%)]\tLoss: 99.260330\nTrain Epoch: 13 [28160/60000 (47%)]\tLoss: 104.113197\nTrain Epoch: 13 [29440/60000 (49%)]\tLoss: 100.327911\n",
      "Train Epoch: 13 [30720/60000 (51%)]\tLoss: 101.018936\nTrain Epoch: 13 [32000/60000 (53%)]\tLoss: 103.025635\n",
      "Train Epoch: 13 [33280/60000 (55%)]\tLoss: 101.245804\nTrain Epoch: 13 [34560/60000 (58%)]\tLoss: 101.966919\nTrain Epoch: 13 [35840/60000 (60%)]\tLoss: 99.768997\n",
      "Train Epoch: 13 [37120/60000 (62%)]\tLoss: 103.051132\nTrain Epoch: 13 [38400/60000 (64%)]\tLoss: 100.405884\n",
      "Train Epoch: 13 [39680/60000 (66%)]\tLoss: 97.388718\nTrain Epoch: 13 [40960/60000 (68%)]\tLoss: 99.312744\n",
      "Train Epoch: 13 [42240/60000 (70%)]\tLoss: 103.130966\nTrain Epoch: 13 [43520/60000 (72%)]\tLoss: 99.622070\n",
      "Train Epoch: 13 [44800/60000 (75%)]\tLoss: 102.894470\nTrain Epoch: 13 [46080/60000 (77%)]\tLoss: 101.307281\n",
      "Train Epoch: 13 [47360/60000 (79%)]\tLoss: 98.843056\nTrain Epoch: 13 [48640/60000 (81%)]\tLoss: 103.308365\n",
      "Train Epoch: 13 [49920/60000 (83%)]\tLoss: 99.722198\nTrain Epoch: 13 [51200/60000 (85%)]\tLoss: 100.111855\nTrain Epoch: 13 [52480/60000 (87%)]\tLoss: 103.325035\n",
      "Train Epoch: 13 [53760/60000 (90%)]\tLoss: 103.282272\nTrain Epoch: 13 [55040/60000 (92%)]\tLoss: 98.977081\n",
      "Train Epoch: 13 [56320/60000 (94%)]\tLoss: 98.986572\nTrain Epoch: 13 [57600/60000 (96%)]\tLoss: 103.222275\n",
      "Train Epoch: 13 [58880/60000 (98%)]\tLoss: 105.692856\n",
      "====> Test set loss: 1.3477\n",
      "Train Epoch: 14 [0/60000 (0%)]\tLoss: 101.718285\nTrain Epoch: 14 [1280/60000 (2%)]\tLoss: 103.814819\n",
      "Train Epoch: 14 [2560/60000 (4%)]\tLoss: 98.635590\nTrain Epoch: 14 [3840/60000 (6%)]\tLoss: 103.863701\n",
      "Train Epoch: 14 [5120/60000 (9%)]\tLoss: 103.123451\nTrain Epoch: 14 [6400/60000 (11%)]\tLoss: 102.181183\nTrain Epoch: 14 [7680/60000 (13%)]\tLoss: 101.241684\n",
      "Train Epoch: 14 [8960/60000 (15%)]\tLoss: 102.052383\nTrain Epoch: 14 [10240/60000 (17%)]\tLoss: 98.196037\nTrain Epoch: 14 [11520/60000 (19%)]\tLoss: 102.780212\n",
      "Train Epoch: 14 [12800/60000 (21%)]\tLoss: 100.034927\nTrain Epoch: 14 [14080/60000 (23%)]\tLoss: 103.986351\nTrain Epoch: 14 [15360/60000 (26%)]\tLoss: 98.740723\n",
      "Train Epoch: 14 [16640/60000 (28%)]\tLoss: 99.971878\nTrain Epoch: 14 [17920/60000 (30%)]\tLoss: 99.390396\n",
      "Train Epoch: 14 [19200/60000 (32%)]\tLoss: 99.631966\nTrain Epoch: 14 [20480/60000 (34%)]\tLoss: 102.439285\n",
      "Train Epoch: 14 [21760/60000 (36%)]\tLoss: 100.075905\nTrain Epoch: 14 [23040/60000 (38%)]\tLoss: 104.229790\n",
      "Train Epoch: 14 [24320/60000 (41%)]\tLoss: 99.877899\nTrain Epoch: 14 [25600/60000 (43%)]\tLoss: 102.177223\nTrain Epoch: 14 [26880/60000 (45%)]\tLoss: 102.324631\n",
      "Train Epoch: 14 [28160/60000 (47%)]\tLoss: 103.569397\nTrain Epoch: 14 [29440/60000 (49%)]\tLoss: 99.535751\nTrain Epoch: 14 [30720/60000 (51%)]\tLoss: 102.052658\n",
      "Train Epoch: 14 [32000/60000 (53%)]\tLoss: 98.932335\nTrain Epoch: 14 [33280/60000 (55%)]\tLoss: 103.738365\nTrain Epoch: 14 [34560/60000 (58%)]\tLoss: 105.220490\n",
      "Train Epoch: 14 [35840/60000 (60%)]\tLoss: 103.307610\nTrain Epoch: 14 [37120/60000 (62%)]\tLoss: 98.980942\nTrain Epoch: 14 [38400/60000 (64%)]\tLoss: 104.291496\n",
      "Train Epoch: 14 [39680/60000 (66%)]\tLoss: 99.221161\nTrain Epoch: 14 [40960/60000 (68%)]\tLoss: 102.128662\nTrain Epoch: 14 [42240/60000 (70%)]\tLoss: 100.456421\n",
      "Train Epoch: 14 [43520/60000 (72%)]\tLoss: 97.762543\nTrain Epoch: 14 [44800/60000 (75%)]\tLoss: 97.707573\nTrain Epoch: 14 [46080/60000 (77%)]\tLoss: 97.128265\n",
      "Train Epoch: 14 [47360/60000 (79%)]\tLoss: 101.155945\nTrain Epoch: 14 [48640/60000 (81%)]\tLoss: 104.800568\nTrain Epoch: 14 [49920/60000 (83%)]\tLoss: 101.019218\n",
      "Train Epoch: 14 [51200/60000 (85%)]\tLoss: 102.167709\nTrain Epoch: 14 [52480/60000 (87%)]\tLoss: 104.149506\n",
      "Train Epoch: 14 [53760/60000 (90%)]\tLoss: 104.146271\nTrain Epoch: 14 [55040/60000 (92%)]\tLoss: 103.802948\n",
      "Train Epoch: 14 [56320/60000 (94%)]\tLoss: 97.727707\nTrain Epoch: 14 [57600/60000 (96%)]\tLoss: 99.447357\nTrain Epoch: 14 [58880/60000 (98%)]\tLoss: 103.290817\n",
      "====> Test set loss: 1.2836\n",
      "Train Epoch: 15 [0/60000 (0%)]\tLoss: 101.607635\nTrain Epoch: 15 [1280/60000 (2%)]\tLoss: 101.671745\nTrain Epoch: 15 [2560/60000 (4%)]\tLoss: 98.983353\n",
      "Train Epoch: 15 [3840/60000 (6%)]\tLoss: 105.001938\nTrain Epoch: 15 [5120/60000 (9%)]\tLoss: 101.148239\nTrain Epoch: 15 [6400/60000 (11%)]\tLoss: 102.503296\n",
      "Train Epoch: 15 [7680/60000 (13%)]\tLoss: 97.754593\nTrain Epoch: 15 [8960/60000 (15%)]\tLoss: 99.069817\nTrain Epoch: 15 [10240/60000 (17%)]\tLoss: 102.755096\n",
      "Train Epoch: 15 [11520/60000 (19%)]\tLoss: 102.386612\nTrain Epoch: 15 [12800/60000 (21%)]\tLoss: 102.111969\nTrain Epoch: 15 [14080/60000 (23%)]\tLoss: 102.204056\n",
      "Train Epoch: 15 [15360/60000 (26%)]\tLoss: 103.444427\nTrain Epoch: 15 [16640/60000 (28%)]\tLoss: 102.406784\n",
      "Train Epoch: 15 [17920/60000 (30%)]\tLoss: 98.724121\nTrain Epoch: 15 [19200/60000 (32%)]\tLoss: 99.346825\nTrain Epoch: 15 [20480/60000 (34%)]\tLoss: 96.792099\n",
      "Train Epoch: 15 [21760/60000 (36%)]\tLoss: 99.577759\nTrain Epoch: 15 [23040/60000 (38%)]\tLoss: 101.752251\n",
      "Train Epoch: 15 [24320/60000 (41%)]\tLoss: 101.577415\nTrain Epoch: 15 [25600/60000 (43%)]\tLoss: 100.734314\n",
      "Train Epoch: 15 [26880/60000 (45%)]\tLoss: 98.704193\nTrain Epoch: 15 [28160/60000 (47%)]\tLoss: 96.965874\nTrain Epoch: 15 [29440/60000 (49%)]\tLoss: 101.398933\n",
      "Train Epoch: 15 [30720/60000 (51%)]\tLoss: 103.320770\nTrain Epoch: 15 [32000/60000 (53%)]\tLoss: 104.385269\n",
      "Train Epoch: 15 [33280/60000 (55%)]\tLoss: 102.682571\nTrain Epoch: 15 [34560/60000 (58%)]\tLoss: 106.773796\n",
      "Train Epoch: 15 [35840/60000 (60%)]\tLoss: 106.652985\nTrain Epoch: 15 [37120/60000 (62%)]\tLoss: 102.418663\n",
      "Train Epoch: 15 [38400/60000 (64%)]\tLoss: 98.506195\nTrain Epoch: 15 [39680/60000 (66%)]\tLoss: 98.628899\n",
      "Train Epoch: 15 [40960/60000 (68%)]\tLoss: 102.206253\nTrain Epoch: 15 [42240/60000 (70%)]\tLoss: 100.107773\nTrain Epoch: 15 [43520/60000 (72%)]\tLoss: 99.734467\n",
      "Train Epoch: 15 [44800/60000 (75%)]\tLoss: 103.136581\nTrain Epoch: 15 [46080/60000 (77%)]\tLoss: 101.256409\nTrain Epoch: 15 [47360/60000 (79%)]\tLoss: 97.958031\n",
      "Train Epoch: 15 [48640/60000 (81%)]\tLoss: 100.812958\nTrain Epoch: 15 [49920/60000 (83%)]\tLoss: 99.648758\nTrain Epoch: 15 [51200/60000 (85%)]\tLoss: 102.649246\n",
      "Train Epoch: 15 [52480/60000 (87%)]\tLoss: 96.334686\nTrain Epoch: 15 [53760/60000 (90%)]\tLoss: 101.225853\n",
      "Train Epoch: 15 [55040/60000 (92%)]\tLoss: 99.395836\nTrain Epoch: 15 [56320/60000 (94%)]\tLoss: 98.249245\nTrain Epoch: 15 [57600/60000 (96%)]\tLoss: 101.936951\n",
      "Train Epoch: 15 [58880/60000 (98%)]\tLoss: 99.353859\n",
      "====> Test set loss: 1.3414\n",
      "Train Epoch: 16 [0/60000 (0%)]\tLoss: 101.900108\nTrain Epoch: 16 [1280/60000 (2%)]\tLoss: 102.519501\nTrain Epoch: 16 [2560/60000 (4%)]\tLoss: 104.742752\n",
      "Train Epoch: 16 [3840/60000 (6%)]\tLoss: 100.794487\nTrain Epoch: 16 [5120/60000 (9%)]\tLoss: 99.374741\nTrain Epoch: 16 [6400/60000 (11%)]\tLoss: 103.659508\n",
      "Train Epoch: 16 [7680/60000 (13%)]\tLoss: 100.333298\nTrain Epoch: 16 [8960/60000 (15%)]\tLoss: 102.732880\nTrain Epoch: 16 [10240/60000 (17%)]\tLoss: 96.857498\n",
      "Train Epoch: 16 [11520/60000 (19%)]\tLoss: 102.462555\nTrain Epoch: 16 [12800/60000 (21%)]\tLoss: 99.155144\nTrain Epoch: 16 [14080/60000 (23%)]\tLoss: 103.796867\n",
      "Train Epoch: 16 [15360/60000 (26%)]\tLoss: 101.308823\nTrain Epoch: 16 [16640/60000 (28%)]\tLoss: 99.614037\nTrain Epoch: 16 [17920/60000 (30%)]\tLoss: 100.295715\n",
      "Train Epoch: 16 [19200/60000 (32%)]\tLoss: 97.337906\nTrain Epoch: 16 [20480/60000 (34%)]\tLoss: 100.590408\n",
      "Train Epoch: 16 [21760/60000 (36%)]\tLoss: 99.367508\nTrain Epoch: 16 [23040/60000 (38%)]\tLoss: 101.127350\nTrain Epoch: 16 [24320/60000 (41%)]\tLoss: 102.632881\n",
      "Train Epoch: 16 [25600/60000 (43%)]\tLoss: 100.328598\nTrain Epoch: 16 [26880/60000 (45%)]\tLoss: 101.574318\nTrain Epoch: 16 [28160/60000 (47%)]\tLoss: 98.780792\n",
      "Train Epoch: 16 [29440/60000 (49%)]\tLoss: 104.677330\nTrain Epoch: 16 [30720/60000 (51%)]\tLoss: 101.819962\nTrain Epoch: 16 [32000/60000 (53%)]\tLoss: 103.481926\n",
      "Train Epoch: 16 [33280/60000 (55%)]\tLoss: 101.405930\nTrain Epoch: 16 [34560/60000 (58%)]\tLoss: 99.280396\nTrain Epoch: 16 [35840/60000 (60%)]\tLoss: 101.180176\n",
      "Train Epoch: 16 [37120/60000 (62%)]\tLoss: 101.238968\nTrain Epoch: 16 [38400/60000 (64%)]\tLoss: 97.481766\n",
      "Train Epoch: 16 [39680/60000 (66%)]\tLoss: 99.040497\nTrain Epoch: 16 [40960/60000 (68%)]\tLoss: 97.676033\nTrain Epoch: 16 [42240/60000 (70%)]\tLoss: 100.313797\n",
      "Train Epoch: 16 [43520/60000 (72%)]\tLoss: 101.357559\nTrain Epoch: 16 [44800/60000 (75%)]\tLoss: 104.807137\nTrain Epoch: 16 [46080/60000 (77%)]\tLoss: 96.424026\n",
      "Train Epoch: 16 [47360/60000 (79%)]\tLoss: 100.687141\nTrain Epoch: 16 [48640/60000 (81%)]\tLoss: 98.051285\n",
      "Train Epoch: 16 [49920/60000 (83%)]\tLoss: 103.299164\nTrain Epoch: 16 [51200/60000 (85%)]\tLoss: 100.344734\nTrain Epoch: 16 [52480/60000 (87%)]\tLoss: 103.066360\n",
      "Train Epoch: 16 [53760/60000 (90%)]\tLoss: 97.797012\nTrain Epoch: 16 [55040/60000 (92%)]\tLoss: 100.920319\n",
      "Train Epoch: 16 [56320/60000 (94%)]\tLoss: 102.040085\nTrain Epoch: 16 [57600/60000 (96%)]\tLoss: 103.790634\nTrain Epoch: 16 [58880/60000 (98%)]\tLoss: 103.144424\n",
      "====> Test set loss: 1.2752\n",
      "Train Epoch: 17 [0/60000 (0%)]\tLoss: 101.487854\nTrain Epoch: 17 [1280/60000 (2%)]\tLoss: 100.150085\nTrain Epoch: 17 [2560/60000 (4%)]\tLoss: 95.407784\n",
      "Train Epoch: 17 [3840/60000 (6%)]\tLoss: 99.036148\nTrain Epoch: 17 [5120/60000 (9%)]\tLoss: 100.096436\n",
      "Train Epoch: 17 [6400/60000 (11%)]\tLoss: 100.913460\nTrain Epoch: 17 [7680/60000 (13%)]\tLoss: 103.870262\nTrain Epoch: 17 [8960/60000 (15%)]\tLoss: 97.844017\n",
      "Train Epoch: 17 [10240/60000 (17%)]\tLoss: 99.816284\nTrain Epoch: 17 [11520/60000 (19%)]\tLoss: 99.108475\nTrain Epoch: 17 [12800/60000 (21%)]\tLoss: 99.780167\n",
      "Train Epoch: 17 [14080/60000 (23%)]\tLoss: 100.633759\nTrain Epoch: 17 [15360/60000 (26%)]\tLoss: 98.325348\nTrain Epoch: 17 [16640/60000 (28%)]\tLoss: 101.157700\n",
      "Train Epoch: 17 [17920/60000 (30%)]\tLoss: 102.376549\nTrain Epoch: 17 [19200/60000 (32%)]\tLoss: 106.037025\nTrain Epoch: 17 [20480/60000 (34%)]\tLoss: 101.482635\n",
      "Train Epoch: 17 [21760/60000 (36%)]\tLoss: 97.687431\nTrain Epoch: 17 [23040/60000 (38%)]\tLoss: 101.268799\nTrain Epoch: 17 [24320/60000 (41%)]\tLoss: 100.295647\n",
      "Train Epoch: 17 [25600/60000 (43%)]\tLoss: 103.711853\nTrain Epoch: 17 [26880/60000 (45%)]\tLoss: 100.340179\nTrain Epoch: 17 [28160/60000 (47%)]\tLoss: 102.787125\n",
      "Train Epoch: 17 [29440/60000 (49%)]\tLoss: 101.741295\nTrain Epoch: 17 [30720/60000 (51%)]\tLoss: 101.609291\nTrain Epoch: 17 [32000/60000 (53%)]\tLoss: 99.908295\n",
      "Train Epoch: 17 [33280/60000 (55%)]\tLoss: 108.589890\nTrain Epoch: 17 [34560/60000 (58%)]\tLoss: 95.919525\nTrain Epoch: 17 [35840/60000 (60%)]\tLoss: 100.848633\n",
      "Train Epoch: 17 [37120/60000 (62%)]\tLoss: 96.944611\nTrain Epoch: 17 [38400/60000 (64%)]\tLoss: 102.304062\n",
      "Train Epoch: 17 [39680/60000 (66%)]\tLoss: 100.156448\nTrain Epoch: 17 [40960/60000 (68%)]\tLoss: 103.505051\n",
      "Train Epoch: 17 [42240/60000 (70%)]\tLoss: 99.490982\nTrain Epoch: 17 [43520/60000 (72%)]\tLoss: 102.899635\nTrain Epoch: 17 [44800/60000 (75%)]\tLoss: 99.938492\n",
      "Train Epoch: 17 [46080/60000 (77%)]\tLoss: 99.708534\nTrain Epoch: 17 [47360/60000 (79%)]\tLoss: 100.710419\n",
      "Train Epoch: 17 [48640/60000 (81%)]\tLoss: 101.613510\nTrain Epoch: 17 [49920/60000 (83%)]\tLoss: 101.591087\nTrain Epoch: 17 [51200/60000 (85%)]\tLoss: 102.853470\n",
      "Train Epoch: 17 [52480/60000 (87%)]\tLoss: 97.537979\nTrain Epoch: 17 [53760/60000 (90%)]\tLoss: 103.696281\n",
      "Train Epoch: 17 [55040/60000 (92%)]\tLoss: 102.066406\nTrain Epoch: 17 [56320/60000 (94%)]\tLoss: 99.591301\n",
      "Train Epoch: 17 [57600/60000 (96%)]\tLoss: 100.292503\nTrain Epoch: 17 [58880/60000 (98%)]\tLoss: 102.567032\n",
      "====> Test set loss: 1.3247\n",
      "Train Epoch: 18 [0/60000 (0%)]\tLoss: 97.829056\nTrain Epoch: 18 [1280/60000 (2%)]\tLoss: 101.936943\n",
      "Train Epoch: 18 [2560/60000 (4%)]\tLoss: 102.864365\nTrain Epoch: 18 [3840/60000 (6%)]\tLoss: 98.918953\n",
      "Train Epoch: 18 [5120/60000 (9%)]\tLoss: 99.218506\nTrain Epoch: 18 [6400/60000 (11%)]\tLoss: 101.788078\nTrain Epoch: 18 [7680/60000 (13%)]\tLoss: 100.193893\n",
      "Train Epoch: 18 [8960/60000 (15%)]\tLoss: 104.653679\nTrain Epoch: 18 [10240/60000 (17%)]\tLoss: 99.115234\n",
      "Train Epoch: 18 [11520/60000 (19%)]\tLoss: 101.287750\nTrain Epoch: 18 [12800/60000 (21%)]\tLoss: 100.362007\n",
      "Train Epoch: 18 [14080/60000 (23%)]\tLoss: 100.089371\nTrain Epoch: 18 [15360/60000 (26%)]\tLoss: 97.044624\n",
      "Train Epoch: 18 [16640/60000 (28%)]\tLoss: 100.516624\nTrain Epoch: 18 [17920/60000 (30%)]\tLoss: 99.815170\n",
      "Train Epoch: 18 [19200/60000 (32%)]\tLoss: 100.691635\nTrain Epoch: 18 [20480/60000 (34%)]\tLoss: 98.653763\n",
      "Train Epoch: 18 [21760/60000 (36%)]\tLoss: 107.818054\nTrain Epoch: 18 [23040/60000 (38%)]\tLoss: 102.907974\nTrain Epoch: 18 [24320/60000 (41%)]\tLoss: 97.229683\n",
      "Train Epoch: 18 [25600/60000 (43%)]\tLoss: 101.603745\nTrain Epoch: 18 [26880/60000 (45%)]\tLoss: 97.812790\n",
      "Train Epoch: 18 [28160/60000 (47%)]\tLoss: 96.614700\nTrain Epoch: 18 [29440/60000 (49%)]\tLoss: 98.044350\nTrain Epoch: 18 [30720/60000 (51%)]\tLoss: 102.965591\n",
      "Train Epoch: 18 [32000/60000 (53%)]\tLoss: 104.912445\nTrain Epoch: 18 [33280/60000 (55%)]\tLoss: 98.646202\n",
      "Train Epoch: 18 [34560/60000 (58%)]\tLoss: 101.849190\nTrain Epoch: 18 [35840/60000 (60%)]\tLoss: 104.372314\n",
      "Train Epoch: 18 [37120/60000 (62%)]\tLoss: 101.282120\nTrain Epoch: 18 [38400/60000 (64%)]\tLoss: 101.272827\n",
      "Train Epoch: 18 [39680/60000 (66%)]\tLoss: 100.092987\nTrain Epoch: 18 [40960/60000 (68%)]\tLoss: 102.100006\nTrain Epoch: 18 [42240/60000 (70%)]\tLoss: 104.977432\n",
      "Train Epoch: 18 [43520/60000 (72%)]\tLoss: 97.905151\nTrain Epoch: 18 [44800/60000 (75%)]\tLoss: 102.013428\nTrain Epoch: 18 [46080/60000 (77%)]\tLoss: 99.995834\n",
      "Train Epoch: 18 [47360/60000 (79%)]\tLoss: 104.363655\nTrain Epoch: 18 [48640/60000 (81%)]\tLoss: 96.092545\nTrain Epoch: 18 [49920/60000 (83%)]\tLoss: 104.935760\n",
      "Train Epoch: 18 [51200/60000 (85%)]\tLoss: 100.038597\nTrain Epoch: 18 [52480/60000 (87%)]\tLoss: 103.049179\n",
      "Train Epoch: 18 [53760/60000 (90%)]\tLoss: 103.071503\nTrain Epoch: 18 [55040/60000 (92%)]\tLoss: 98.627884\n",
      "Train Epoch: 18 [56320/60000 (94%)]\tLoss: 104.131699\nTrain Epoch: 18 [57600/60000 (96%)]\tLoss: 99.217209\n",
      "Train Epoch: 18 [58880/60000 (98%)]\tLoss: 100.178665\n",
      "====> Test set loss: 1.2506\n",
      "Train Epoch: 19 [0/60000 (0%)]\tLoss: 97.393906\nTrain Epoch: 19 [1280/60000 (2%)]\tLoss: 100.034584\nTrain Epoch: 19 [2560/60000 (4%)]\tLoss: 99.202606\n",
      "Train Epoch: 19 [3840/60000 (6%)]\tLoss: 100.080505\nTrain Epoch: 19 [5120/60000 (9%)]\tLoss: 99.280167\nTrain Epoch: 19 [6400/60000 (11%)]\tLoss: 101.543365\n",
      "Train Epoch: 19 [7680/60000 (13%)]\tLoss: 103.591133\nTrain Epoch: 19 [8960/60000 (15%)]\tLoss: 103.014130\n",
      "Train Epoch: 19 [10240/60000 (17%)]\tLoss: 102.753586\nTrain Epoch: 19 [11520/60000 (19%)]\tLoss: 101.837364\n",
      "Train Epoch: 19 [12800/60000 (21%)]\tLoss: 99.615959\nTrain Epoch: 19 [14080/60000 (23%)]\tLoss: 104.449089\nTrain Epoch: 19 [15360/60000 (26%)]\tLoss: 100.883041\n",
      "Train Epoch: 19 [16640/60000 (28%)]\tLoss: 102.142708\nTrain Epoch: 19 [17920/60000 (30%)]\tLoss: 102.202606\n",
      "Train Epoch: 19 [19200/60000 (32%)]\tLoss: 102.050659\nTrain Epoch: 19 [20480/60000 (34%)]\tLoss: 100.017487\nTrain Epoch: 19 [21760/60000 (36%)]\tLoss: 95.511658\n",
      "Train Epoch: 19 [23040/60000 (38%)]\tLoss: 98.230927\nTrain Epoch: 19 [24320/60000 (41%)]\tLoss: 100.737656\n",
      "Train Epoch: 19 [25600/60000 (43%)]\tLoss: 100.463455\nTrain Epoch: 19 [26880/60000 (45%)]\tLoss: 100.924362\nTrain Epoch: 19 [28160/60000 (47%)]\tLoss: 102.129089\n",
      "Train Epoch: 19 [29440/60000 (49%)]\tLoss: 103.039597\nTrain Epoch: 19 [30720/60000 (51%)]\tLoss: 99.915901\nTrain Epoch: 19 [32000/60000 (53%)]\tLoss: 99.523026\n",
      "Train Epoch: 19 [33280/60000 (55%)]\tLoss: 98.418793\nTrain Epoch: 19 [34560/60000 (58%)]\tLoss: 99.321381\nTrain Epoch: 19 [35840/60000 (60%)]\tLoss: 101.676331\n",
      "Train Epoch: 19 [37120/60000 (62%)]\tLoss: 100.462967\nTrain Epoch: 19 [38400/60000 (64%)]\tLoss: 102.730118\nTrain Epoch: 19 [39680/60000 (66%)]\tLoss: 100.514053\n",
      "Train Epoch: 19 [40960/60000 (68%)]\tLoss: 99.612495\nTrain Epoch: 19 [42240/60000 (70%)]\tLoss: 98.068108\nTrain Epoch: 19 [43520/60000 (72%)]\tLoss: 100.497139\n",
      "Train Epoch: 19 [44800/60000 (75%)]\tLoss: 99.732513\nTrain Epoch: 19 [46080/60000 (77%)]\tLoss: 97.798988\n",
      "Train Epoch: 19 [47360/60000 (79%)]\tLoss: 100.168808\nTrain Epoch: 19 [48640/60000 (81%)]\tLoss: 102.818840\nTrain Epoch: 19 [49920/60000 (83%)]\tLoss: 98.674789\n",
      "Train Epoch: 19 [51200/60000 (85%)]\tLoss: 98.301331\nTrain Epoch: 19 [52480/60000 (87%)]\tLoss: 101.360550\nTrain Epoch: 19 [53760/60000 (90%)]\tLoss: 99.899643\n",
      "Train Epoch: 19 [55040/60000 (92%)]\tLoss: 103.089272\nTrain Epoch: 19 [56320/60000 (94%)]\tLoss: 102.885284\nTrain Epoch: 19 [57600/60000 (96%)]\tLoss: 104.767662\n",
      "Train Epoch: 19 [58880/60000 (98%)]\tLoss: 101.947235\n",
      "====> Test set loss: 1.2886\n",
      "Train Epoch: 20 [0/60000 (0%)]\tLoss: 101.775162\nTrain Epoch: 20 [1280/60000 (2%)]\tLoss: 105.218353\nTrain Epoch: 20 [2560/60000 (4%)]\tLoss: 100.447845\n",
      "Train Epoch: 20 [3840/60000 (6%)]\tLoss: 102.804123\nTrain Epoch: 20 [5120/60000 (9%)]\tLoss: 100.166115\nTrain Epoch: 20 [6400/60000 (11%)]\tLoss: 101.411140\n",
      "Train Epoch: 20 [7680/60000 (13%)]\tLoss: 103.683235\nTrain Epoch: 20 [8960/60000 (15%)]\tLoss: 99.224899\n",
      "Train Epoch: 20 [10240/60000 (17%)]\tLoss: 100.507233\nTrain Epoch: 20 [11520/60000 (19%)]\tLoss: 99.166214\nTrain Epoch: 20 [12800/60000 (21%)]\tLoss: 100.586395\n",
      "Train Epoch: 20 [14080/60000 (23%)]\tLoss: 99.232262\nTrain Epoch: 20 [15360/60000 (26%)]\tLoss: 101.571892\n",
      "Train Epoch: 20 [16640/60000 (28%)]\tLoss: 102.133247\nTrain Epoch: 20 [17920/60000 (30%)]\tLoss: 97.010719\nTrain Epoch: 20 [19200/60000 (32%)]\tLoss: 104.078201\n",
      "Train Epoch: 20 [20480/60000 (34%)]\tLoss: 100.052429\nTrain Epoch: 20 [21760/60000 (36%)]\tLoss: 100.157730\n",
      "Train Epoch: 20 [23040/60000 (38%)]\tLoss: 102.495949\nTrain Epoch: 20 [24320/60000 (41%)]\tLoss: 103.371704\n",
      "Train Epoch: 20 [25600/60000 (43%)]\tLoss: 102.396118\nTrain Epoch: 20 [26880/60000 (45%)]\tLoss: 99.082840\n",
      "Train Epoch: 20 [28160/60000 (47%)]\tLoss: 100.959221\nTrain Epoch: 20 [29440/60000 (49%)]\tLoss: 98.661469\n",
      "Train Epoch: 20 [30720/60000 (51%)]\tLoss: 94.830231\nTrain Epoch: 20 [32000/60000 (53%)]\tLoss: 101.195404\nTrain Epoch: 20 [33280/60000 (55%)]\tLoss: 104.668571\n",
      "Train Epoch: 20 [34560/60000 (58%)]\tLoss: 96.365753\nTrain Epoch: 20 [35840/60000 (60%)]\tLoss: 97.912903\n",
      "Train Epoch: 20 [37120/60000 (62%)]\tLoss: 100.474426\nTrain Epoch: 20 [38400/60000 (64%)]\tLoss: 99.034134\n",
      "Train Epoch: 20 [39680/60000 (66%)]\tLoss: 99.558441\nTrain Epoch: 20 [40960/60000 (68%)]\tLoss: 100.588356\n",
      "Train Epoch: 20 [42240/60000 (70%)]\tLoss: 99.052094\nTrain Epoch: 20 [43520/60000 (72%)]\tLoss: 98.876633\n",
      "Train Epoch: 20 [44800/60000 (75%)]\tLoss: 100.383202\nTrain Epoch: 20 [46080/60000 (77%)]\tLoss: 100.907066\nTrain Epoch: 20 [47360/60000 (79%)]\tLoss: 100.184898\n",
      "Train Epoch: 20 [48640/60000 (81%)]\tLoss: 99.260132\nTrain Epoch: 20 [49920/60000 (83%)]\tLoss: 101.122513\nTrain Epoch: 20 [51200/60000 (85%)]\tLoss: 99.479637\n",
      "Train Epoch: 20 [52480/60000 (87%)]\tLoss: 102.712425\nTrain Epoch: 20 [53760/60000 (90%)]\tLoss: 99.945587\nTrain Epoch: 20 [55040/60000 (92%)]\tLoss: 104.027649\n",
      "Train Epoch: 20 [56320/60000 (94%)]\tLoss: 104.445259\n",
      "Train Epoch: 20 [57600/60000 (96%)]\tLoss: 101.774475\nTrain Epoch: 20 [58880/60000 (98%)]\tLoss: 99.829079\n",
      "====> Test set loss: 1.2871\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "for epoch in range(1, args.epochs +1):\n",
    "    train(epoch)\n",
    "    test(epoch)\n",
    "    with torch.no_grad():\n",
    "        sample = torch.randn(81,20).to(device)\n",
    "        #20次元の潜在空間のデータを64個作成して、GPUに送る\n",
    "        sample = model.decode(sample).cpu()\n",
    "        #ランダムな潜在変数から画像を生成する。\n",
    "        save_image(sample.view(81,1,28,28),'results/sample_' + str(epoch) + '.png',nrow=9)\n",
    "        #生成した６４個のデータを記録しておく"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}